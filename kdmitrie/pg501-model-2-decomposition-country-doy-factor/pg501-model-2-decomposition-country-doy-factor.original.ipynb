{"metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"name": "python", "version": "3.10.12", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "kaggle": {"accelerator": "none", "dataSources": [{"sourceId": 85723, "databundleVersionId": 10652996, "sourceType": "competition"}, {"sourceId": 3325325, "sourceType": "datasetVersion", "datasetId": 2007861}, {"sourceId": 10629074, "sourceType": "datasetVersion", "datasetId": 6581134}, {"sourceId": 218469538, "sourceType": "kernelVersion"}, {"sourceId": 219013464, "sourceType": "kernelVersion"}, {"sourceId": 220025463, "sourceType": "kernelVersion"}, {"sourceId": 220117756, "sourceType": "kernelVersion"}], "dockerImageVersionId": 30822, "isInternetEnabled": true, "language": "python", "sourceType": "notebook", "isGpuEnabled": false}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "# 1. Libraries import", "metadata": {"_uuid": "db3ea09c-cb8e-4c30-9742-50720b40ba5c", "_cell_guid": "397b74f6-3fa7-4a46-815a-d54ac9e35191", "trusted": true, "collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"cell_type": "code", "source": "# Import standart libraries\nimport numpy as np\nimport pandas as pd\nimport pickle\nfrom sklearn.metrics import mean_absolute_percentage_error\nfrom scipy.optimize import minimize\nimport sys\n\nsys.path.append('./input/pgs501-lib')\nfrom lib.config import CFG\nfrom lib import holiday, processing\n\n!cp -R ./input/pgs501-lib/data ./\n!mkdir ./data/optimal", "metadata": {"_uuid": "aba27122-68dc-400d-9360-e6656e0393c0", "_cell_guid": "b5aa2596-d7d5-42b0-9042-c76726c7e253", "trusted": true, "collapsed": false, "execution": {"iopub.status.busy": "2025-02-01T11:17:34.456004Z", "iopub.execute_input": "2025-02-01T11:17:34.456303Z", "iopub.status.idle": "2025-02-01T11:17:36.211002Z", "shell.execute_reply.started": "2025-02-01T11:17:34.456277Z", "shell.execute_reply": "2025-02-01T11:17:36.209471Z"}, "jupyter": {"outputs_hidden": false}}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "# 2. Basic settings", "metadata": {"_uuid": "c831e31d-aa75-4ed9-8091-cc585d5b0d4e", "_cell_guid": "34faae41-b489-44f1-a7ab-b07926a02046", "trusted": true, "collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"cell_type": "code", "source": "# SOFT prediction assumes the sales are constant after 2018-01-01; HARD prediction assumes the linear trend\nSOFT_PREDICTION = True\n\n# Perform CV or not\ndo_cv = False\n\n# Perform main prediction or not\ndo_prediction = True\n\n# Prefix to save the data at\nprefix = 'soft_prediction' if SOFT_PREDICTION else 'hard_prediction'", "metadata": {"_uuid": "51e119e0-5577-46ff-b2ab-e1f55b710b73", "_cell_guid": "0904b1bf-59dd-4592-a54a-f67efd4e19b0", "trusted": true, "collapsed": false, "execution": {"iopub.status.busy": "2025-02-01T11:17:36.212581Z", "iopub.execute_input": "2025-02-01T11:17:36.213304Z", "iopub.status.idle": "2025-02-01T11:17:36.218567Z", "shell.execute_reply.started": "2025-02-01T11:17:36.213272Z", "shell.execute_reply": "2025-02-01T11:17:36.217406Z"}, "jupyter": {"outputs_hidden": false}}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "# 3. Helper functions for dataframe preparation, prediction and optimization\n\n## 3.1. `prepare_df`\nPrepares the dataframe by adding the necessary columns. Returns the modified dataframe, the list of column groups and the reasonable initial guess of the parameters.\n\n- `df` - the input dataframe.\n- `countries` - the list of countries to perform the operations on.", "metadata": {"_uuid": "c40e8522-54db-426e-ba66-6d6011ecb5d3", "_cell_guid": "24921763-a2e5-406f-9037-53f9aeeb1bdf", "trusted": true, "collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"cell_type": "code", "source": "def prepare_df(df, countries):\n    # 1. GDP factor\n    gdp_factor = processing.get_gdp_factor(CFG.gdp_csv, countries, CFG.years)\n    df = df.join(gdp_factor, on=['country', 'year'], how='left')\n    \n    # 2. Holidays\n    hdays_cols = []\n    for country in countries:\n        daynum, hmap, hds_names = holiday.get_holiday_map(CFG.countries_2l[country], CFG.years)\n    \n        hnames = [f'hol_{country}_{n}_{hds_names[n - len(hdays_cols)]}' for n in range(len(hdays_cols), len(hdays_cols) + hmap.shape[1])]\n        hdays_cols += hnames\n    \n        hdf = pd.DataFrame(hmap, columns=hnames).reset_index(names='daynum').set_index('daynum')\n        df = df.join(hdf, on='daynum', how='left')\n        df.loc[df.country != country, hnames] = 0\n    \n    hdays_cols = [col for col in hdays_cols if 'BEGIN' not in col]\n    print(f'Number of holidays = {len(hdays_cols)}')\n    \n    # 3. Store\n    store_cols = []\n    for st in CFG.stores:\n        df[st] = (df['store'] == st).astype(int)\n        store_cols.append(st)\n    \n    # 4. Products\n    product_cols = []\n    product_cols_restricted = {\n        'Holographic Goose': ['cos t'],\n        'Kaggle': ['sin t/2', 'cos t/2'],\n        'Kaggle Tiers': ['sin t/2', 'cos t/2'],\n        'Kerneler': ['sin t'],\n        'Kerneler Dark Mode': ['sin t']\n    }\n    \n    for n, product in enumerate(CFG.products):\n        col = f'pr_{n} const'\n        df[col] = (df['product'] == product).astype(int)\n        product_cols.append(col)\n    \n        sincos_features = ['sin t', 'cos t', 'sin t/2', 'cos t/2']\n        for sc in sincos_features:\n            if sc in product_cols_restricted[product]:\n                col = f'pr_{n} {sc}'\n                df[col] = (df['product'] == product).astype(int) * df[sc]\n                product_cols.append(col)\n    \n    # 5. Weekday\n    week_cols = []\n    for n in range(4, 7):\n        col = f'wd_{n}'\n        df[col] = (df['weekday'] == n).astype(int)\n        week_cols.append(col)\n    \n    # 6. Day number\n    daynum_cols = ['daynum']\n        \n    # Column groups\n    col_groups = [\n        ['gdp_factor'],\n        store_cols,\n        product_cols,\n        week_cols,\n        daynum_cols,\n        hdays_cols,\n    ]\n\n    initial_guess = [\n        [-1.9, 0.01], # GDP\n        [0.33, 0.33], # Stores\n        [0.1 for pc in product_cols[1:]],  # Product cols\n        [0 for wd in range(3)], # Weekday\n        [3, 1e-2], # ReLU\n        [0 for hd in hdays_cols],  # Holidays\n    ]\n\n    return df, col_groups, initial_guess", "metadata": {"_uuid": "4fe1d3cb-65b2-4c27-94af-8b06f9a7011f", "_cell_guid": "d59d8d7b-5cd0-412a-b6fc-7ea5564a3c67", "trusted": true, "collapsed": false, "execution": {"iopub.status.busy": "2025-02-01T11:17:36.219522Z", "iopub.execute_input": "2025-02-01T11:17:36.219859Z", "iopub.status.idle": "2025-02-01T11:17:36.234461Z", "shell.execute_reply.started": "2025-02-01T11:17:36.219829Z", "shell.execute_reply": "2025-02-01T11:17:36.233386Z"}, "jupyter": {"outputs_hidden": false}}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## 3.2. `predict` \nThe main function that performs the prediction.\n\n- `coef` - the parameters of the model.\n- `x` - input data.\n- `round` - optional parameter determines, whether the result is rounded to the nearest int or not.", "metadata": {"_uuid": "ef81de9b-acbd-4173-9f24-d363bdb4770e", "_cell_guid": "4377d10e-faa7-46b0-b5e1-0fd5da36796e", "trusted": true, "collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"cell_type": "code", "source": "def predict(coef, x, round=False):\n    cgn, ign = 0, 0\n    x_groups = []\n    coef_groups = []\n    for cg, ig in zip(col_groups, initial_guess):\n        x_groups.append(x[:, cgn: cgn + len(cg)])\n        coef_groups.append(coef[ign: ign + len(ig)])\n        cgn += len(cg)\n        ign += len(ig)\n\n    m1 = x_groups[0][:, 0] * coef_groups[0][1] + coef_groups[0][0]\n    m2 = x_groups[1] @ np.array((coef_groups[1][0], coef_groups[1][1], 1 - coef_groups[1][0] - coef_groups[1][1]))\n    m3 = x_groups[2][:, 0] + x_groups[2][:, 1:] @ coef_groups[2]\n    m4 = 1 + x_groups[3] @ coef_groups[3]\n\n    daynum = x_groups[4][:, 0]\n    if SOFT_PREDICTION:\n        daynum = np.clip(daynum, a_min=0, a_max=2922)\n    m5 = 1 + np.clip((daynum / 365 - coef_groups[4][0]) * coef_groups[4][1], a_min=0, a_max=None)\n    m6 = 1 + x_groups[5] @ coef_groups[5] # Holidays\n\n    y_pred = m1 * m2 * m3 * m4 * m5 * m6\n    return np.round(y_pred).astype(int) if round else y_pred", "metadata": {"_uuid": "e7237d62-1442-45a9-9e9d-b27d6c38e064", "_cell_guid": "f2d9e679-94b9-42b5-b86d-1e043627fbb5", "trusted": true, "collapsed": false, "execution": {"iopub.status.busy": "2025-02-01T11:17:36.236896Z", "iopub.execute_input": "2025-02-01T11:17:36.237248Z", "iopub.status.idle": "2025-02-01T11:17:36.256484Z", "shell.execute_reply.started": "2025-02-01T11:17:36.237221Z", "shell.execute_reply": "2025-02-01T11:17:36.255539Z"}, "jupyter": {"outputs_hidden": false}}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## 3.3. `get_score`\nReturns the MAPE score using current values of parameters\n\n- `coef` - the parameters of the model.\n- `x` - input data.\n- `y_true` - ground true values of the prediction.\n- `round` - optional parameter determines, whether the result is rounded to the nearest int or not.\n- `reg` - optional  parameter could be passed that is used for LASSO regularization.", "metadata": {"_uuid": "3ee2b071-34c5-4f7a-8289-6dd08384d39e", "_cell_guid": "3bda48e9-9a89-4ec6-bab5-99f7181569ba", "trusted": true, "collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"cell_type": "code", "source": "def get_score(coef, x, y_true, round=False, reg=0):\n    y_pred = predict(coef, x, round)\n    score = mean_absolute_percentage_error(y_true, y_pred)\n    #score += reg * np.sum(np.abs(coef[4: 130]))\n    return score", "metadata": {"_uuid": "fdeff477-d69e-45d9-bf6b-2d1d4ef5c585", "_cell_guid": "653c78a3-563c-4697-a3ad-e61654535e35", "trusted": true, "collapsed": false, "execution": {"iopub.status.busy": "2025-02-01T11:17:36.262021Z", "iopub.execute_input": "2025-02-01T11:17:36.262351Z", "iopub.status.idle": "2025-02-01T11:17:36.282406Z", "shell.execute_reply.started": "2025-02-01T11:17:36.262317Z", "shell.execute_reply": "2025-02-01T11:17:36.281278Z"}, "jupyter": {"outputs_hidden": false}}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## 3.4. `optimize`\nPerforms the optimization procedure and returns the object with optimal parameters.\nIf `opt_groups` is None, optimizes all available parameters. Otherwise only the specified groups of parameters are optimizeed, while others are fixed. This is done in the purpose of performance.\n\n- `coef0` - the initial values of model's parameters.\n- `x_train` - train input data.\n- `y_train` - ground true values of the train data.\n- `reg` - optional  parameter could be passed that is used for LASSO regularization.\n- `max_iter` - optional limit of iterations.\n- `opt_groups` - the list indicating what groups of parameters to train.\n\n`on_epoch` - helper function that is called after each iteration.", "metadata": {"_uuid": "f91b1087-5c07-40ab-bd64-48ea5c870576", "_cell_guid": "f0412502-7aa1-4f72-a2fb-4a78500e7e61", "trusted": true, "collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"cell_type": "code", "source": "def on_epoch(intermediate_result):\n    #print(f'{intermediate_result.fun}')\n    pass\n\n\ndef optimize(coef0, x_train, y_train, reg=0, maxiter=30, opt_groups=None):\n    if opt_groups is None:\n        # Optimize all\n        opt_indices = list(range(len(cols)))\n    else:\n        # Optimize only the indices from the selected groups\n        opt_indices = []\n        ign = 0\n        for ig_id, ig in enumerate(initial_guess):\n            if ig_id in opt_groups:\n                opt_indices += list(range(ign, ign + len(ig)))\n            ign += len(ig)\n    local_coef = coef0.copy()\n\n    def objective1(x):\n        return get_score(x, x_train, y_train, reg=reg)\n\n    def objective2(x):\n        local_coef[opt_indices] = x\n        return get_score(local_coef, x_train, y_train, reg=reg)\n\n    res = minimize(objective1 if opt_groups is None else objective2,\n                   x0=local_coef if opt_groups is None else local_coef[opt_indices],\n                   callback=on_epoch,\n                   options={'maxiter': maxiter, })\n\n    if opt_groups is not None:\n        local_coef[opt_indices] = res.x\n        res.x = local_coef\n\n    return res", "metadata": {"_uuid": "9f20e3c8-db23-4a16-bbdb-0da5f340549f", "_cell_guid": "f2952756-2d11-4c10-9d07-ba250c50dbc6", "trusted": true, "collapsed": false, "execution": {"iopub.status.busy": "2025-02-01T11:17:36.28352Z", "iopub.execute_input": "2025-02-01T11:17:36.283905Z", "iopub.status.idle": "2025-02-01T11:17:36.299131Z", "shell.execute_reply.started": "2025-02-01T11:17:36.283871Z", "shell.execute_reply": "2025-02-01T11:17:36.297796Z"}, "jupyter": {"outputs_hidden": false}}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## 3.5. Optimization pipeline (of the 1st level)\nPerform the whole optimization cycle. This cycle consists of several optimization steps, at each of which a group of column sets is optimized.\n\n- `df_train` - the train dataframe.\n- `df_test` - the test dataframe.\n- `cols` - the column groups list.\n- `initial_guess` - the initial guess of the parameters.\n- `optimization_steps` - the list of optimization steps.\n- `lasso_reg` - optional  parameter could be passed that is used for LASSO regularization.\n- `print_params` - whether to print params after each step or not.", "metadata": {"_uuid": "1c0b0eab-5cc6-461a-a15f-aed107b51156", "_cell_guid": "65c41617-70df-44dc-9c55-2f6eeb8a5c60", "trusted": true, "collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"cell_type": "code", "source": "def optimization_pipeline(df_train, df_test, cols, initial_guess, optimization_steps, lasso_reg=0, print_params=False):\n    x_train = df_train[cols].to_numpy()\n    y_train = df_train['num_sold'].to_numpy()\n    x_test = df_test[cols].to_numpy()\n    y_test = df_test['num_sold'].to_numpy()\n\n    coef0 = np.concatenate(initial_guess)\n\n    for step in optimization_steps:\n        res = optimize(coef0, x_train, y_train, reg=lasso_reg, opt_groups=step['groups'], maxiter=step['niter'])\n        if print_params:\n            print(res.x)\n        coef0 = res.x\n        score1 = get_score(res.x, x_train, y_train, round=False, reg=0)\n        score2 = get_score(res.x, x_train, y_train, round=True, reg=0)\n        print(f'\\tstep {step[\"name\"]}: {res.fun}\\t{score1}\\t{score2}')\n    train_score = get_score(res.x, x_train, y_train, True)\n    test_score = None if np.isnan(y_test).any() else get_score(res.x, x_test, y_test, True)\n    return res, (train_score, test_score)", "metadata": {"_uuid": "ae5eff25-aa9e-474a-97f7-f4185d4280de", "_cell_guid": "805711cc-fde3-4ebe-ada0-2d48d1eae0b0", "trusted": true, "collapsed": false, "execution": {"iopub.status.busy": "2025-02-01T11:17:36.300427Z", "iopub.execute_input": "2025-02-01T11:17:36.300774Z", "iopub.status.idle": "2025-02-01T11:17:36.322299Z", "shell.execute_reply.started": "2025-02-01T11:17:36.300738Z", "shell.execute_reply": "2025-02-01T11:17:36.321208Z"}, "jupyter": {"outputs_hidden": false}}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## 3.5. Optimization pipeline (of the 2nd level)\nPerform the whole optimization cycle several times, each time with different countries.\nThis could be useful for training on the subsets of countries.\n\n- `df_train` - the train dataframe.\n- `df_test` - the test dataframe.\n- `cols` - the column groups list.\n- `countries_groups` - the list of countries groups.\n- `initial_guess` - the initial guess of the parameters.\n- `optimization_steps` - the list of optimization steps.", "metadata": {"_uuid": "bc16dc91-9b50-40ed-9455-6e8e07fb0830", "_cell_guid": "c1979094-4231-4cea-8da5-9eb64f2cbbcf", "trusted": true, "collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"cell_type": "code", "source": "def optimization_pipeline2(df_train, df_test, cols, countries_groups, initial_guess, optimization_steps):\n    x = []\n    df1, df2 = df_train.copy(), df_test.copy()\n    df1['prediction'] = 0\n    df2['prediction'] = 0\n    for countries in countries_groups:\n        if len(df2[df2.country.isin(countries)]) == 0:\n            continue\n        print(f'\\tDo optimization on the countries: ' + ', '.join(countries))\n        res, (train_score, test_score) = optimization_pipeline(df1[df1.country.isin(countries)], \n                                                               df2[df2.country.isin(countries)], \n                                                               cols, \n                                                               initial_guess, \n                                                               optimization_steps)\n        \n        df1.loc[df1.country.isin(countries), 'prediction'] = predict(res.x, df1[df1.country.isin(countries)][cols].to_numpy(), True)\n        df2.loc[df2.country.isin(countries), 'prediction'] = predict(res.x, df2[df2.country.isin(countries)][cols].to_numpy(), True)\n        x.append(res.x)\n\n    res = {'x': x}\n    train_score = mean_absolute_percentage_error(df1['num_sold'], df1['prediction'])\n    test_score = None if pd.isna(df2['num_sold']).any() else mean_absolute_percentage_error(df2['num_sold'], df2['prediction'])\n\n    return res, (train_score, test_score)\n\ndef predict2(coef, df, cols, countries_groups, round=False):\n    df1 = df.copy()\n    df1['prediction'] = 0.0\n    for x, countries in zip(coef, countries_groups):\n        df1.loc[df1.country.isin(countries), 'prediction'] = predict(x, df1[df1.country.isin(countries)][cols].to_numpy(), round)\n    return df1['prediction']", "metadata": {"_uuid": "88d417d6-b759-4881-895a-8dce9a8234a2", "_cell_guid": "a9c3a13c-4dfa-4b42-b475-ccf83c971139", "trusted": true, "collapsed": false, "execution": {"iopub.status.busy": "2025-02-01T11:17:36.323613Z", "iopub.execute_input": "2025-02-01T11:17:36.324015Z", "iopub.status.idle": "2025-02-01T11:17:36.344589Z", "shell.execute_reply.started": "2025-02-01T11:17:36.323979Z", "shell.execute_reply": "2025-02-01T11:17:36.343554Z"}, "jupyter": {"outputs_hidden": false}}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "# 4. Prepare data", "metadata": {"_uuid": "51a3f530-f60e-4cc3-8c09-8901180b06c3", "_cell_guid": "ffac3114-c93d-49b8-93f6-e22545375283", "trusted": true, "collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"cell_type": "code", "source": "# First, we use external library to add the columns\ndf = processing.data_read_and_combine(CFG.train_csv, CFG.test_csv)\ndf = processing.data_add_date_features(df)\n\n# Second, we use local `prepare_df`\ndf, col_groups, initial_guess = prepare_df(df.copy(), CFG.countries)\n\n# Drop some data for Kenya\n#df = df[(df.year > 2012) | (df.country != 'Kenya')]  # Drop Kenya's 2010-2012\n\n# Keep the original DF\ndf_orig = df.copy()\ndf_submit = df[(df.test == 1)]\ndf = df[(df.test == 0) & (~df['num_sold'].isna())]\n\n# THe whole list of the columns\ncols = sum(col_groups, [])", "metadata": {"_uuid": "bb015fc2-1b96-4257-9efc-60739a6161c9", "_cell_guid": "7f2749e1-5555-426c-8420-a270b9b81806", "trusted": true, "collapsed": false, "execution": {"iopub.status.busy": "2025-02-01T11:17:36.345831Z", "iopub.execute_input": "2025-02-01T11:17:36.346196Z", "iopub.status.idle": "2025-02-01T11:17:39.972268Z", "shell.execute_reply.started": "2025-02-01T11:17:36.346159Z", "shell.execute_reply": "2025-02-01T11:17:39.971409Z"}, "jupyter": {"outputs_hidden": false}}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "# 5. CV\n\nWe set the parameters for CV and perform it. The results are saved in `./data/optimal`", "metadata": {"_uuid": "de4a7102-1271-446c-ae9c-fe789a09b9a1", "_cell_guid": "13beee11-5151-41be-9707-2d62792c79a0", "trusted": true, "collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"cell_type": "code", "source": "optimization_steps = [\n    {'name': 'gspw', 'groups': [0, 1, 2, 3], 'niter': 120},\n    {'name': 'daynum', 'groups': [4], 'niter': 100},\n    {'name': 'holidays', 'groups': [5], 'niter': 100},\n    {'name': 'all', 'groups': None, 'niter': 100},\n]\n\ncountries_groups = [\n    ['Canada', 'Finland', 'Italy', 'Kenya', 'Norway', 'Singapore'],\n    ['Kenya'], \n]\n\nif do_cv:\n    train_scores, test_scores = [], []\n    df['oof'] = None\n    for year in CFG.years[:-3]:\n        print(f'Year = {year}')\n\n        res, (train_score, test_score) = optimization_pipeline2(df[df.year != year], \n                                                                df[df.year == year], \n                                                                cols, \n                                                                countries_groups, \n                                                                initial_guess, \n                                                                optimization_steps)\n        with open(f'./data/optimal/{prefix}_{year}_param.pkl', 'wb') as f:\n            pickle.dump(res, f)\n\n        df_orig['pred'] = predict2(res['x'], df_orig, cols, countries_groups, False)\n        df_orig.to_csv(f'./data/optimal/{prefix}_{year}_imputation.csv')\n\n        if year > 0:\n            df.loc[df.year == year, 'oof'] = predict2(res['x'], df[df.year == year], cols, countries_groups, True)\n            train_scores.append(train_score)\n            test_scores.append(test_score)\n            print(f'{year}: {train_score=} {test_score=}')\n        else:\n            print(f'Full data: {train_score=}')\n            \n    print(f'\\nAVG: train={np.mean(train_scores)}, test={np.mean(test_scores)}\\n\\n')\n    df.to_csv(f'./data/optimal/{prefix}_result.csv')", "metadata": {"_uuid": "0df98b41-b56e-45b8-9730-bf872f8f8c30", "_cell_guid": "e100af97-df76-471f-9619-1ff25d17fbcb", "trusted": true, "collapsed": false, "execution": {"iopub.status.busy": "2025-02-01T11:17:39.973433Z", "iopub.execute_input": "2025-02-01T11:17:39.973815Z", "iopub.status.idle": "2025-02-01T11:17:39.982434Z", "shell.execute_reply.started": "2025-02-01T11:17:39.973755Z", "shell.execute_reply": "2025-02-01T11:17:39.981452Z"}, "jupyter": {"outputs_hidden": false}}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "# 6. Main prediction\nPerform the main prediction. Here, the values for maximum iterations are higher.\n\nAt the output, there are two files: 'clear' and 'raw'.", "metadata": {"_uuid": "60ce1e63-d541-44b0-a154-31f8e0c95692", "_cell_guid": "91351297-3f49-4f19-8353-fa9b148a9fae", "trusted": true, "collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"cell_type": "code", "source": "optimization_steps = [\n    {'name': 'gspw', 'groups': [0, 1, 2, 3], 'niter': 120},\n    {'name': 'daynum', 'groups': [4], 'niter': 100},\n    {'name': 'holidays', 'groups': [5], 'niter': 150},\n    {'name': 'all', 'groups': None, 'niter': 150},\n]\n\nif do_prediction:\n    res, (train_score, test_score) = optimization_pipeline2(df, df_submit, cols, countries_groups, initial_guess, optimization_steps)\n    with open(f'submission_param.pkl', 'wb') as f:\n        pickle.dump(res, f)\n    \n    # Prepare submissions\n    df_submit['num_sold_raw'] = predict2(res['x'], df_submit, cols, countries_groups, True)\n    df_submit.to_csv(f'{prefix}_submission_raw.csv')\n\n    df_submit['num_sold'] = np.round(df_submit['num_sold_raw']).astype(int)\n    df_submit[['id', 'num_sold']].to_csv(f'{prefix}_submission_clear.csv', index=False)", "metadata": {"_uuid": "ac7d090b-288d-4225-a702-f0fbaf54a051", "_cell_guid": "e1632dda-f6cc-40c5-a21e-f54a9a726b0a", "trusted": true, "collapsed": false, "execution": {"iopub.status.busy": "2025-02-01T11:17:39.983434Z", "iopub.execute_input": "2025-02-01T11:17:39.983675Z"}, "jupyter": {"outputs_hidden": false}}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## Check, that the beginning and the end of file is okay.", "metadata": {"_uuid": "4ce4b027-23c2-4ca8-8384-9fbbce27a1c7", "_cell_guid": "03a09c7b-0187-43d0-b495-9275ba7681db", "trusted": true, "collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"cell_type": "code", "source": "!head {prefix}_submission_clear.csv\n\n\"\"\"id,num_sold\n230130,154\n230131,1001\n230132,759\n230133,444\n230134,519\n230135,313\n230136,2029\n230137,1540\n230138,900\"\"\";", "metadata": {"_uuid": "eaa67d9d-ef05-405a-af28-990b1710bed6", "_cell_guid": "fbd93f56-79ba-4de6-a326-fc72ae0e1323", "trusted": true, "collapsed": false, "jupyter": {"outputs_hidden": false}}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "!tail {prefix}_submission_clear.csv\n\n\"\"\" For SOFT prediction:\n328670,379\n328671,2404\n328672,2138\n328673,1093\n328674,1270\n328675,448\n328676,2840\n328677,2527\n328678,1291\n328679,1501\"\"\"\n\n\"\"\" For HARD prediction\n328670,396\n328671,2506\n328672,2230\n328673,1139\n328674,1324\n328675,467\n328676,2962\n328677,2635\n328678,1346\n328679,1565\"\"\";", "metadata": {"_uuid": "6df45913-b676-42ad-b5a1-8f2ed45c5e40", "_cell_guid": "84abb390-e87a-4164-b9c5-2e689f7a184f", "trusted": true, "collapsed": false, "jupyter": {"outputs_hidden": false}}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "# Ready to submit!", "metadata": {"_uuid": "1ae7d96d-96ad-4d52-af6f-7811cfaeb8a4", "_cell_guid": "fdde8980-f806-4230-862e-c1efad4fff16", "trusted": true, "collapsed": false, "jupyter": {"outputs_hidden": false}}}]}