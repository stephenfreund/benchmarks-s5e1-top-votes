{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da3",
   "metadata": {},
   "source": [
    "This solution is largely based on [Konstantin Dmitriev's starter model](https://www.kaggle.com/code/kdmitrie/pg501-model-2-decomposition-country-doy-factor?scriptVersionId=220159752). I recommend reading through his notebook first as it provides wonderful explanations for many of the factors included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T09:05:24.621516Z",
     "iopub.status.busy": "2025-02-01T09:05:24.621084Z",
     "iopub.status.idle": "2025-02-01T09:05:24.627155Z",
     "shell.execute_reply": "2025-02-01T09:05:24.625697Z",
     "shell.execute_reply.started": "2025-02-01T09:05:24.62148Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import holidays\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T09:05:24.657909Z",
     "iopub.status.busy": "2025-02-01T09:05:24.657383Z",
     "iopub.status.idle": "2025-02-01T09:05:24.665858Z",
     "shell.execute_reply": "2025-02-01T09:05:24.664601Z",
     "shell.execute_reply.started": "2025-02-01T09:05:24.657873Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def fit_mape_linear_model(X, y):\n",
    "    # Ensure X is a 2D array\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y).squeeze()\n",
    "    \n",
    "    # Add bias term to X\n",
    "    X = np.column_stack((np.ones(X.shape[0]), X))\n",
    "    \n",
    "    # Define the MAPE loss function\n",
    "    def mape_loss(beta, X, y):\n",
    "        y_pred = X @ beta\n",
    "        return np.mean(np.abs((y - y_pred) / y)) * 100\n",
    "    \n",
    "    # Initial guess for parameters\n",
    "    init_params = np.zeros(X.shape[1])\n",
    "    \n",
    "    # Minimize the MAPE loss\n",
    "    result = minimize(mape_loss, init_params, args=(X, y), method='L-BFGS-B')\n",
    "    \n",
    "    # Extract optimized parameters\n",
    "    beta_opt = result.x\n",
    "    \n",
    "    # Create and return an sklearn LinearRegression model\n",
    "    model = LinearRegression()\n",
    "    model.coef_ = beta_opt[1:]\n",
    "    model.intercept_ = beta_opt[0]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T09:05:24.667603Z",
     "iopub.status.busy": "2025-02-01T09:05:24.667245Z",
     "iopub.status.idle": "2025-02-01T09:05:25.105018Z",
     "shell.execute_reply": "2025-02-01T09:05:25.103884Z",
     "shell.execute_reply.started": "2025-02-01T09:05:24.667575Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./input/playground-series-s5e1/train.csv', parse_dates=['date'])\n",
    "test = pd.read_csv('./input/playground-series-s5e1/test.csv', parse_dates=['date'])\n",
    "train = train.dropna().reset_index(drop=True)\n",
    "df = pd.concat([train, test], sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f565",
   "metadata": {},
   "source": [
    "##### Useful Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T09:05:25.107543Z",
     "iopub.status.busy": "2025-02-01T09:05:25.107175Z"
    }
   },
   "outputs": [],
   "source": [
    "df['year'] = df['date'].dt.year\n",
    "df['n_day'] = (df['date'] - df['date'].min()).dt.days\n",
    "df['weekday'] = df['date'].dt.weekday\n",
    "df['day_of_year'] = df['date'].dt.dayofyear\n",
    "\n",
    "# Generate Wave Columns\n",
    "wave_columns = []\n",
    "# subtract leap dates\n",
    "df.loc[df['date'] > dt.datetime(2012, 2, 29), 'n_day'] -= 1\n",
    "df.loc[df['date'] > dt.datetime(2016, 2, 29), 'n_day'] -= 1\n",
    "\n",
    "for i in range(1, 10):\n",
    "\n",
    "    df[f'wave_sin{i}'] = np.sin(np.pi * i * df['n_day'] / 365)\n",
    "    df[f'wave_cos{i}'] = np.cos(np.pi * i * df['n_day'] / 365)\n",
    "    wave_columns.append(f'wave_sin{i}')\n",
    "    wave_columns.append(f'wave_cos{i}')\n",
    "\n",
    "# Near Holiday\n",
    "df['near_holiday'] = 0\n",
    "for country in df['country'].unique():\n",
    "    days = [day for day in holidays.CountryHoliday(country, years=df['year'].unique())] \n",
    "    for day in days:\n",
    "        df.loc[(df.country == country) & (df['date'].dt.date < day + dt.timedelta(days=10)) & (df['date'].dt.date > day - dt.timedelta(days=10)), 'near_holiday'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c0",
   "metadata": {},
   "source": [
    "### Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a459",
   "metadata": {},
   "source": [
    "##### GDP Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def get_gdp_per_capita(country,year):\n",
    "    alpha3 = {'Canada': 'CAN', 'Finland': 'FIN',\n",
    "              'Italy': 'ITA', 'Kenya': 'KEN', \n",
    "              'Norway': 'NOR', 'Singapore': 'SGP'}\n",
    "    url=\"https://api.worldbank.org/v2/country/{0}/indicator/NY.GDP.PCAP.CD?date={1}&format=json\".format(alpha3[country],year)\n",
    "    response = requests.get(url).json()\n",
    "    return response[1][0]['value']\n",
    "\n",
    "gdp = np.array([[get_gdp_per_capita(country, year) for year in df['year'].unique()] for country in df['country'].unique()])\n",
    "gdp_df = pd.DataFrame(gdp, columns=df['year'].unique(), index=df['country'].unique())\n",
    "for year in df['year'].unique():\n",
    "    for country in df['country'].unique():\n",
    "        df.loc[(df['year'] == year) & (df['country'] == country), 'gdp'] = gdp_df.loc[country, year]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee6",
   "metadata": {},
   "source": [
    "From broccoli beef's [discussion post comment](https://www.kaggle.com/competitions/playground-series-s5e1/discussion/555500#3091632). Using the following least MAPE linear fit improves predictions for kenya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gdp_factor'] =  (-17643.346899+85.42355636*df['gdp']) / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "grouped_data = df.groupby(['date', 'year', 'country'])['num_sold'].sum().reset_index()\n",
    "total_per_day = df.groupby('year')['num_sold'].sum().reset_index()\n",
    "grouped_data = grouped_data.merge(total_per_day, on=['year'], suffixes=['', '_total']).reset_index()\n",
    "grouped_data = grouped_data.merge(df[['date', 'country', 'gdp_factor']], on=['date', 'country'])\n",
    "\n",
    "for country in df['country'].unique():\n",
    "    country_data = grouped_data[((grouped_data['country'] == country) & (grouped_data['date'] < dt.datetime(2017, 1, 1)))]\n",
    "    axs[0].plot(country_data['date'], country_data['num_sold'] / country_data['num_sold_total'], '-', label=country)\n",
    "    axs[0].plot(country_data['date'], country_data['gdp_factor'] / country_data['num_sold_total'], 'b--')\n",
    "axs[0].set_title('Amt Sold Per Country')\n",
    "axs[0].legend()\n",
    "\n",
    "for country in df['country'].unique():\n",
    "    country_data = grouped_data[((grouped_data['country'] == country) & (grouped_data['date'] < dt.datetime(2017, 1, 1)))]\n",
    "    axs[1].plot(country_data['date'], country_data['num_sold'] / country_data['gdp_factor'], '-', label=country)\n",
    "axs[1].set_title('Amt Sold Per Country normalized by GDP factor')\n",
    "axs[1].legend()\n",
    "\n",
    "df['ratio'] = df['gdp_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2433",
   "metadata": {},
   "source": [
    "##### Store Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_can_ken = df[~df['country'].isin(['Canada', 'Kenya'])]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 6))\n",
    "store_data = df_no_can_ken.groupby(['date', 'store'])['num_sold'].sum().reset_index()\n",
    "total_per_day = df_no_can_ken.groupby('date')['num_sold'].sum().reset_index()\n",
    "store_data = store_data.merge(total_per_day, on=['date'], suffixes=['', '_total'])\n",
    "\n",
    "# Calculate store factor\n",
    "store_data['store_factor'] = store_data['num_sold'] / store_data['num_sold_total']\n",
    "store_df = store_data.groupby('store')['store_factor'].mean().reset_index()\n",
    "store_data.drop('store_factor', axis=1, inplace=True)\n",
    "store_data = store_data.merge(store_df, on=['store'])\n",
    "print(f\"Store factor sum is {store_df['store_factor'].sum()}\")\n",
    "\n",
    "# Merge store factor into df\n",
    "df = df.drop('store_factor', axis=1, errors='ignore')\n",
    "df = df.merge(store_df, on=['store'])\n",
    "df['ratio'] = df['store_factor']\n",
    "\n",
    "for store in df['store'].unique():\n",
    "    data = store_data[store_data['store'] == store]\n",
    "    axs[0].plot(data['date'], data['num_sold'] / data['num_sold_total'], '.', label=f'Store {store}')\n",
    "axs[0].set_title('Relative Amt Sold Per Store')\n",
    "axs[0].legend()\n",
    "\n",
    "# Normalize by current ratio\n",
    "for store in df['store'].unique():\n",
    "    data = store_data[store_data['store'] == store]\n",
    "    axs[1].plot(data['date'], data['num_sold'] /  data['num_sold_total'] /  data['store_factor'], '.', label=f'Store {store}')\n",
    "axs[1].set_title('Rel Amt Sold Per Store normalized by store factor') \n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073b",
   "metadata": {},
   "source": [
    "##### Product Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ratio'] = df['store_factor'] * df['gdp_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "df_no_can_ken = df[~df['country'].isin(['Canada', 'Kenya'])]\n",
    "total_per_day = df_no_can_ken.groupby('date')['total'].sum().reset_index()\n",
    "df_no_can_ken = df_no_can_ken.merge(total_per_day, on=['date'], suffixes=['', '_per_day'])\n",
    "df_no_can_ken['total_perc_per_day'] = df_no_can_ken['total'] / df_no_can_ken['total_per_day'] \n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "# fit wave columns to each product\n",
    "df['product_factor'] = None\n",
    "for product in df['product'].unique():\n",
    "\n",
    "    df_product = df_no_can_ken[((df_no_can_ken['product'] == product) & (df_no_can_ken['date'] < dt.datetime(2017, 1, 1)))].groupby('date')\n",
    "    X = df_product[wave_columns].mean()\n",
    "    y = df_product['total_perc_per_day'].sum()\n",
    "    \n",
    "    model = fit_mape_linear_model(X, y)\n",
    "    df.loc[df['product'] == product, 'product_factor'] = model.predict(df[df['product'] == product][wave_columns])\n",
    "\n",
    "    axs[0].plot(df_product['date'].unique().index, y, '-', label=product)\n",
    "    axs[0].plot(df_product['date'].unique().index, model.predict(X), 'b--')\n",
    "axs[0].set_title('Amt Sold Per Product')\n",
    "axs[0].legend()\n",
    "\n",
    "# Visualize the result\n",
    "df_no_can_ken = df[~df['country'].isin(['Canada', 'Kenya'])]\n",
    "total_per_day = df_no_can_ken.groupby('date')['total'].sum().reset_index()\n",
    "df_no_can_ken = df_no_can_ken.merge(total_per_day, on=['date'], suffixes=['', '_per_day'])\n",
    "df_no_can_ken['total_perc_per_day'] = df_no_can_ken['total'] / df_no_can_ken['total_per_day'] \n",
    "for product in df['product'].unique():\n",
    "    df_product = df_no_can_ken[((df_no_can_ken['product'] == product) & (df_no_can_ken['date'] < dt.datetime(2017, 1, 1)))].groupby('date')\n",
    "    y = df_product['total_perc_per_day'].sum()\n",
    "    product_factor = df_product['product_factor'].mean()\n",
    "    axs[1].plot(df_product['date'].unique().index, y / product_factor, '-', label=product)\n",
    "axs[1].set_title('Amt Sold Per Product normalized by Product factor')\n",
    "axs[1].legend()\n",
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e5",
   "metadata": {},
   "source": [
    "##### Day of Week Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "df_no_can_ken_hol = df[~((df['country'].isin(['Canada', 'Kenya'])) | (df['near_holiday']))]\n",
    "\n",
    "mean_per_weekday = df_no_can_ken_hol.groupby('weekday')['total'].mean().reset_index()\n",
    "mean_mon_thur = mean_per_weekday[mean_per_weekday['weekday'] < 4]['total'].mean()\n",
    "ratio_per_weekday = mean_per_weekday.copy()\n",
    "ratio_per_weekday['day_of_week_factor'] = ratio_per_weekday['total'] / mean_mon_thur\n",
    "ratio_per_weekday = ratio_per_weekday.drop('total', axis=1)\n",
    "\n",
    "df = df.drop('day_of_week_factor', axis=1, errors='ignore')\n",
    "df = df.merge(ratio_per_weekday, on='weekday')\n",
    "\n",
    "grouped_data = df_no_can_ken_hol.groupby(['date'])['total'].mean().reset_index()\n",
    "grouped_data = grouped_data[grouped_data['date'] < dt.datetime(2017, 1, 1)]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "axs[0].plot(grouped_data['date'], grouped_data['total'], '-')\n",
    "axs[0].set_title('Mean Total Per Day')\n",
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "# Visualize the result\n",
    "df_no_can_ken_hol = df[~((df['country'].isin(['Canada', 'Kenya'])) | (df['near_holiday']))]\n",
    "\n",
    "grouped_data = df_no_can_ken_hol.groupby(['date'])['total'].mean().reset_index()\n",
    "grouped_data = grouped_data[grouped_data['date'] < dt.datetime(2017, 1, 1)]\n",
    "\n",
    "axs[1].plot(grouped_data['date'], grouped_data['total'], '-')\n",
    "axs[1].set_title('Mean Total Per Day normalized by weekday factor')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ab",
   "metadata": {},
   "source": [
    "##### Sincos factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "df_no_can_ken_hol = df[~((df['country'].isin(['Canada', 'Kenya'])) | (df['near_holiday']))]\n",
    "grouped_data = df_no_can_ken_hol[df_no_can_ken_hol['date'] < dt.datetime(2017, 1, 1)].groupby(['date'])\n",
    "X = grouped_data[wave_columns].mean()\n",
    "y = grouped_data['total'].mean()\n",
    "\n",
    "model = fit_mape_linear_model(X, y)\n",
    "\n",
    "df['sincos_factor'] = model.predict(df[wave_columns])\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "axs[0].plot(grouped_data['date'].unique().index, y, '-')\n",
    "axs[0].set_title('Mean Total Per Day')\n",
    "axs[0].plot(grouped_data['date'].unique().index, model.predict(X), 'r--')\n",
    "\n",
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "# Visualize the result\n",
    "df_no_can_ken_hol = df[~((df['country'].isin(['Canada', 'Kenya'])) | (df['near_holiday']))]\n",
    "grouped_data = df_no_can_ken_hol.groupby(['date'])['total'].mean().reset_index()\n",
    "\n",
    "axs[1].plot(grouped_data['date'], grouped_data['total'], '-')\n",
    "axs[1].set_title('Mean Total Per Day normalized by sincos factor')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033a",
   "metadata": {},
   "source": [
    "##### Trend Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2c",
   "metadata": {},
   "source": [
    "This factor is only meant to make calculating the subsequent factors easier.\n",
    "\n",
    "\n",
    "I attempted to include this factor in the final product for one of my submissions. Doing this while also removing the 1.06 factor (see const_factor under the \"Prediction and Submission\" section) resulted in my best public LB score (0.04422). However, as expected, this was very overfit (private LB  ~0.054)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "grouped_data = df.groupby(['date', 'n_day'])['total'].mean().reset_index()\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "axs[0].plot(grouped_data['date'], grouped_data['total'], '-')\n",
    "\n",
    "train = grouped_data[(grouped_data['date'] < dt.datetime(2017, 1, 1)) & (grouped_data['date'] > dt.datetime(2012, 12, 31))]\n",
    "X = train['n_day'].to_numpy().reshape(-1, 1)\n",
    "y = train['total']\n",
    "\n",
    "model = Ridge(alpha=0.1)\n",
    "model.fit(X, y)\n",
    "\n",
    "df['trend_factor'] = model.predict(df['n_day'].to_numpy().reshape(-1, 1))\n",
    "df.loc[df['date'] < dt.datetime(2013, 1, 1), 'trend_factor'] = 1\n",
    "axs[0].plot(grouped_data['date'], model.predict(grouped_data['n_day'].to_numpy().reshape(-1, 1)), 'r--')\n",
    "axs[0].set_title('Mean Total Over Time Uncorrected')\n",
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor'] * df['trend_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "# Visualize the result\n",
    "grouped_data = df.groupby(['date', 'n_day'])['total'].mean().reset_index()\n",
    "axs[1].plot(grouped_data['date'], grouped_data['total'], '-')\n",
    "axs[1].set_title('Mean Total Over Time Corrected by Trend Factor')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3001",
   "metadata": {},
   "source": [
    "##### Country Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor'] * df['trend_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "grouped_data = df[df['product'] == \"Kaggle\"].groupby(['date', 'country'])['total'].sum().reset_index()\n",
    "total_per_day = df[df['product'] == \"Kaggle\"].groupby('date')['total'].sum().reset_index()\n",
    "grouped_data = grouped_data.merge(total_per_day, on=['date'], suffixes=['', '_per_day'])\n",
    "grouped_data = grouped_data[grouped_data['date'] < dt.datetime(2017, 1, 1)]\n",
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor'] * df['trend_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "for country in df['country'].unique():\n",
    "    country_data = grouped_data[grouped_data['country'] == country]\n",
    "    axs[0].plot(country_data['date'], country_data['total'] / country_data['total_per_day'], '-', label=country)\n",
    "axs[0].set_title('Mean Total Per Day Per Country')\n",
    "axs[0].legend()\n",
    "\n",
    "country_factor = df[(df['product'] == 'Kaggle')].groupby('country').total.sum().rename('country_factor')\n",
    "country_factor = country_factor / country_factor.median()\n",
    "df = df.drop('country_factor', axis=1, errors='ignore')\n",
    "df = df.merge(country_factor, on='country')\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor'] * df['country_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "# Visualize the result\n",
    "grouped_data = df[df['product'] == \"Kaggle\"].groupby(['date', 'country'])['total'].sum().reset_index()\n",
    "total_per_day = df[df['product'] == \"Kaggle\"].groupby('date')['total'].sum().reset_index()\n",
    "grouped_data = grouped_data.merge(total_per_day, on=['date'], suffixes=['', '_per_day'])\n",
    "grouped_data = grouped_data[grouped_data['date'] < dt.datetime(2017, 1, 1)]\n",
    "\n",
    "for country in df['country'].unique():\n",
    "    country_data = grouped_data[grouped_data['country'] == country]\n",
    "    axs[1].plot(country_data['date'], country_data['total'] / country_data['total_per_day'], '-', label=country)\n",
    "axs[1].set_title('Mean Total Per Day Per Country normalized by country factor')\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f7",
   "metadata": {},
   "source": [
    "##### Holiday factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc30",
   "metadata": {},
   "source": [
    "My handling of the following two factors (holiday factor and New Years factor) is inspired by JZ's [first place solution](https://www.kaggle.com/code/ivyzang/1st-place-solution-less-is-more/notebook) to a previous competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the years and countries\n",
    "years = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
    "countries = df['country'].unique()\n",
    "# Initialize an empty list to hold DataFrames\n",
    "dfs = []\n",
    "# Generate holidays for each country and year\n",
    "for year in years:\n",
    "    for country in countries:\n",
    "        for date, holiday_name in sorted(holidays.CountryHoliday(country, years=year).items()):\n",
    "\n",
    "            df_0 = pd.DataFrame({\"date\": [date], \"country\": [\n",
    "                country]})\n",
    "            dfs.append(df_0)\n",
    "\n",
    "# Concatenate all the DataFrames\n",
    "df_holidays = pd.concat(dfs, ignore_index=True)\n",
    "# Convert 'date' column to datetime\n",
    "df_holidays['date'] = pd.to_datetime(df_holidays['date'])\n",
    "df_holidays['tmp'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if 'holiday_' in column:\n",
    "        df = df.drop(column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# holidays\n",
    "holidays_columns = []\n",
    "for i in range(0, 10):\n",
    "    column = 'holiday_{}'.format(i)\n",
    "    shifted = df_holidays.rename(columns={'tmp': column})\n",
    "    shifted['date'] = shifted['date'] + dt.timedelta(days=i)\n",
    "    df = pd.merge(df, shifted, on=['country', 'date'], how='left')\n",
    "    df[column].fillna(0, inplace=True)\n",
    "    df[column] = df[column]\n",
    "    holidays_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor'] * df['country_factor'] * df['trend_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "axs[0].plot(df['date'], df['total'], '-')\n",
    "axs[0].set_title('Total Over Time')\n",
    "\n",
    "# fit linear model to total using holidays\n",
    "\n",
    "train = df[(df['date'] > dt.datetime(2012, 12, 31)) & (df['date'] < dt.datetime(2017, 1, 1))]\n",
    "X = train[holidays_columns]\n",
    "y = train['total']\n",
    "model = fit_mape_linear_model(X, y)\n",
    "\n",
    "df['holiday_factor'] = model.predict(df[holidays_columns])\n",
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor'] * df['country_factor'] * df['holiday_factor'] * df['trend_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "axs[1].plot(df['date'], df['total'], '-')\n",
    "axs[1].set_title('Total Over Time normalized by holiday factor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc",
   "metadata": {},
   "source": [
    "##### New Years Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_years_columns = []\n",
    "for day in range(25, 32):\n",
    "    column = 'day_12_{}'.format(day)\n",
    "    df[column] = ((df['date'].dt.month == 12) & (df['date'].dt.day == day)).astype(float)\n",
    "    new_years_columns.append(column)\n",
    "for day in range(1, 11):\n",
    "    column = 'day_1_{}'.format(day)\n",
    "    df[column] = ((df['date'].dt.month == 1) & (df['date'].dt.day  == day)).astype(float)\n",
    "    new_years_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor'] * df['country_factor'] * df['holiday_factor'] * df['trend_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "axs[0].plot(df['date'], df['total'], '-')\n",
    "axs[0].set_title('Total Over Time')\n",
    "\n",
    "train = df[(df['date'] > dt.datetime(2012, 12, 31)) & (df['date'] < dt.datetime(2017, 1, 1))]\n",
    "X = train[new_years_columns]\n",
    "y = train['total']\n",
    "model = fit_mape_linear_model(X, y)\n",
    "\n",
    "df['new_years_factor'] = model.predict(df[new_years_columns])\n",
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor'] * df['country_factor'] * df['holiday_factor'] * df['new_years_factor'] * df['trend_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "axs[1].plot(df['date'], df['total'], '-')\n",
    "axs[1].set_title('Total Over Time normalized by new years factor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c",
   "metadata": {},
   "source": [
    "### Prediction and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ratio'] = df['country_factor'] * df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor'] * df['holiday_factor'] * df['new_years_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "# Multiplying the predictions by 1.06 seems to improve the public LB score.\n",
    "# I'm not entirely sure why, but I suspect it has to do with the fact that the model is off by ~6% by 2017 (as shown in the right plot of the sincos section above).\n",
    "const_factor = df['total'].median() * 1.06\n",
    "\n",
    "df['prediction'] = df['ratio'] * const_factor \n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 5))\n",
    "ax.plot(df['date'], df['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "mape_train = mean_absolute_percentage_error(df[(df['date'] < dt.datetime(2017, 1, 1)) & (~pd.isna(df.num_sold))].num_sold, df[(df['date'] < dt.datetime(2017, 1, 1)) & (~pd.isna(df.num_sold))].prediction)\n",
    "\n",
    "print(f'{mape_train=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prediction'] = np.round(df['prediction']).astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = df[df['date'] >= dt.datetime(2017, 1, 1)][['id', 'prediction']].rename(columns={'prediction': 'num_sold'})\n",
    "\n",
    "# timestampt submission filename\n",
    "submission_filename = dt.datetime.now().strftime('%Y_%m_%d_%H_%M_%S') + '_submission.csv'\n",
    "\n",
    "submission.to_csv(f\"{submission_filename}\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10652996,
     "sourceId": 85723,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
