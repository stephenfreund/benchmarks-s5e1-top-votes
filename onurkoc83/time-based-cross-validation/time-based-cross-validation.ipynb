{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-01T02:17:29.092932Z",
     "iopub.status.busy": "2025-01-01T02:17:29.092534Z",
     "iopub.status.idle": "2025-01-01T02:17:29.419789Z",
     "shell.execute_reply": "2025-01-01T02:17:29.418499Z",
     "shell.execute_reply.started": "2025-01-01T02:17:29.092884Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv('./input/playground-series-s5e1/train.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Sort by date\n",
    "df = df.sort_values('date')\n",
    "\n",
    "# Categorical features\n",
    "cat_features = ['country', 'product', 'store']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0c",
   "metadata": {},
   "source": [
    "# NaN Values for unique categories \n",
    "\n",
    "This code checks and removes categories that contain NaN (missing) values:\n",
    "\n",
    "1. First, it counts how many rows we have in total\n",
    "2. Then finds any categories that have NaN values in their 'num_sold' column\n",
    "3. These categories are completely removed from the dataset\n",
    "4. These removed categories won't be used in cross-validation\n",
    "\n",
    "This way, we ensure that our cross-validation process only works with complete data, avoiding any potential issues with missing values during model training and validation.\n",
    "\n",
    "Before dropping NaN categories → Shows total row count\n",
    "After dropping NaN categories → Shows remaining rows after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-01T02:17:31.963002Z",
     "iopub.status.busy": "2025-01-01T02:17:31.962419Z",
     "iopub.status.idle": "2025-01-01T02:17:32.608914Z",
     "shell.execute_reply": "2025-01-01T02:17:32.60777Z",
     "shell.execute_reply.started": "2025-01-01T02:17:31.962944Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Shape before dropping NaN categories: {len(df)}\")\n",
    "# Calculate NaN percentage for each category combination\n",
    "nan_percentages = df.groupby(cat_features)['num_sold'].apply(\n",
    "    lambda x: (x.isna().sum() / len(x)) * 100\n",
    ").reset_index(name='nan_percentage')\n",
    "\n",
    "# Get category combinations to drop (those with NaN values)\n",
    "categories_to_drop = nan_percentages[nan_percentages['nan_percentage'] > 0]\n",
    "\n",
    "\n",
    "# Drop rows with these category combinations from the original dataframe\n",
    "for _, row in categories_to_drop.iterrows():\n",
    "    mask = True\n",
    "    for feat in cat_features:\n",
    "        mask &= (df[feat] == row[feat])\n",
    "    df = df[~mask]\n",
    "\n",
    "\n",
    "print(f\"Shape after dropping NaN categories: {len(df)}\")\n",
    "categories_to_drop.sort_values('nan_percentage')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-01T02:17:33.862491Z",
     "iopub.status.busy": "2025-01-01T02:17:33.861995Z",
     "iopub.status.idle": "2025-01-01T02:17:33.869869Z",
     "shell.execute_reply": "2025-01-01T02:17:33.868569Z",
     "shell.execute_reply.started": "2025-01-01T02:17:33.862451Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_date_features(data):\n",
    "\n",
    "   # 1. Quarter (Çeyrek)\n",
    "   data['quarter'] = data['date'].dt.quarter\n",
    "\n",
    "   # 2. Month (Ay)\n",
    "   data['month'] = data['date'].dt.month \n",
    "\n",
    "   # 3. Day (Gün)\n",
    "   data['day'] = data['date'].dt.day\n",
    "\n",
    "   # 4. Day of week (Haftanın günü)\n",
    "   data['day_of_week'] = data['date'].dt.dayofweek\n",
    "\n",
    "   # 5. Day of year (Yılın günü)\n",
    "   data['day_of_year'] = data['date'].dt.dayofyear\n",
    "\n",
    "   # 6. Week of month (Ayın haftası)\n",
    "   data['week_of_month'] = data['date'].dt.day.apply(lambda x: (x-1)//7 + 1)\n",
    "\n",
    "   # 7. Week of year (Yılın haftası)\n",
    "   data['week_of_year'] = data['date'].dt.isocalendar().week\n",
    "\n",
    "   # 8. Is weekend (Hafta sonu mu?)\n",
    "   data['is_weekend'] = data['date'].dt.dayofweek.isin([5,6]).astype(int)\n",
    "\n",
    "   # 9. Is month end (Ayın son günü mü?)\n",
    "   data['is_month_end'] = data['date'].dt.is_month_end.astype(int)\n",
    "\n",
    "   # 10. Year (Yıl)\n",
    "   data['year'] = data['date'].dt.year\n",
    "   \n",
    "   date_feats = [ \n",
    "                 'quarter',\n",
    "                 'month',\n",
    "                 'day',\n",
    "                 'day_of_week',\n",
    "                 'day_of_year',\n",
    "                 'week_of_month',\n",
    "                 'week_of_year',\n",
    "                 'is_weekend',\n",
    "                 'is_month_end',\n",
    "                 'year']\n",
    "   \n",
    "   return data, date_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8c",
   "metadata": {},
   "source": [
    "# Time-Based Cross Validation \n",
    "\n",
    "This code implements a special type of cross-validation for time series data. Here's how it works:\n",
    "\n",
    "## Main Idea\n",
    "- The data is split by time periods\n",
    "- Each unqiue category (country,product,store) is handled separately\n",
    "- We use a sliding window approach to create train and validation sets\n",
    "- The process is repeated 5 times (5 folds)\n",
    "\n",
    "## How the Splits Work\n",
    "1. For each category:\n",
    "   - Takes 40% of the data for initial training\n",
    "   - Uses 20% for validation\n",
    "   - Slides forward for each fold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-01T02:33:31.458318Z",
     "iopub.status.busy": "2025-01-01T02:33:31.457883Z",
     "iopub.status.idle": "2025-01-01T02:33:31.46852Z",
     "shell.execute_reply": "2025-01-01T02:33:31.467089Z",
     "shell.execute_reply.started": "2025-01-01T02:33:31.458284Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='./input/expanding-window/expanding_window.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-01T02:17:37.449666Z",
     "iopub.status.busy": "2025-01-01T02:17:37.449312Z",
     "iopub.status.idle": "2025-01-01T02:18:25.671478Z",
     "shell.execute_reply": "2025-01-01T02:18:25.669857Z",
     "shell.execute_reply.started": "2025-01-01T02:17:37.449635Z"
    }
   },
   "outputs": [],
   "source": [
    "# Label encode categorical features\n",
    "label_encoders = {}\n",
    "for feature in cat_features:\n",
    "    label_encoders[feature] = LabelEncoder()\n",
    "    df[f'{feature}_encoded'] = label_encoders[feature].fit_transform(df[feature])\n",
    "\n",
    "# Update cat_features to use encoded versions\n",
    "encoded_cat_features = [f'{feature}_encoded' for feature in cat_features]\n",
    "\n",
    "# ANSI color codes\n",
    "BLUE = '\\033[94m'\n",
    "RED = '\\033[91m'\n",
    "GREEN = '\\033[92m'\n",
    "RESET = '\\033[0m'  # Reset color formatting\n",
    "\n",
    "# Function to create splits for a single category combination\n",
    "def create_splits(category_data, n_splits=5):\n",
    "    splits = []\n",
    "    dates = category_data['date'].sort_values().unique()\n",
    "    n_dates = len(dates)\n",
    "    \n",
    "    # Calculate validation size (approximately 20% of total data)\n",
    "    val_size = int(n_dates * 0.2)\n",
    "    \n",
    "    # Calculate initial training size\n",
    "    initial_train_size = int(n_dates * 0.4)  # Start with 40% of data\n",
    "    \n",
    "    # Calculate step size for sliding\n",
    "    remaining_points = n_dates - initial_train_size - val_size\n",
    "    if remaining_points < n_splits - 1:\n",
    "        return []\n",
    "        \n",
    "    step_size = remaining_points // (n_splits - 1)\n",
    "    \n",
    "    for i in range(n_splits):\n",
    "        train_end_idx = initial_train_size + (i * step_size)\n",
    "        val_end_idx = train_end_idx + val_size\n",
    "        \n",
    "        if val_end_idx > n_dates:\n",
    "            break\n",
    "            \n",
    "        train_dates = dates[:train_end_idx]\n",
    "        val_dates = dates[train_end_idx:val_end_idx]\n",
    "        \n",
    "        splits.append((train_dates, val_dates))\n",
    "    \n",
    "    return splits\n",
    "\n",
    "# Initialize lists to store results\n",
    "all_mapes = []\n",
    "\n",
    "# Get unique category combinations\n",
    "category_combinations = df.groupby(cat_features).size().reset_index()[cat_features]\n",
    "\n",
    "# Create 5 folds\n",
    "for fold in range(5):\n",
    "    print(f\"\\nFold {fold + 1}:\")\n",
    "    print()\n",
    "    # Initialize lists to store train and validation indices for this fold\n",
    "    train_indices = []\n",
    "    val_indices = []\n",
    "    \n",
    "    # Process each category combination\n",
    "    for idx, cat_combo in category_combinations.iterrows():\n",
    "        # Get data for this category combination\n",
    "        mask = True\n",
    "        for feat, value in cat_combo.items():\n",
    "            mask = mask & (df[feat] == value)\n",
    "        category_data = df[mask].copy()\n",
    "            \n",
    "        # Create splits for this category\n",
    "        splits = create_splits(category_data, n_splits=5)\n",
    "        \n",
    "        if splits and fold < len(splits):  # Only proceed if we have enough data for this fold\n",
    "            train_dates, val_dates = splits[fold]\n",
    "            \n",
    "            # Add indices to our lists\n",
    "            train_indices.extend(category_data[category_data['date'].isin(train_dates)].index)\n",
    "            val_indices.extend(category_data[category_data['date'].isin(val_dates)].index)\n",
    "    \n",
    "    # Create train and validation sets\n",
    "    train_data = df.loc[train_indices]\n",
    "    val_data = df.loc[val_indices]\n",
    "    \n",
    "    # Print date ranges and shapes with colors\n",
    "    print(f\"{BLUE}Train date range: {train_data['date'].dt.date.min()} to {train_data['date'].dt.date.max()}\")\n",
    "    print(f\"Val date range: {val_data['date'].dt.date.min()} to {val_data['date'].dt.date.max()}{RESET}\")\n",
    "    print()  # Add empty line between date ranges and shapes\n",
    "    print(f\"{RED}Train shape: {train_data.shape}\")\n",
    "    print(f\"Val shape: {val_data.shape}{RESET}\")\n",
    "    print()  # Add empty line between shapes and MAPE\n",
    "    \n",
    "    # Apply the function to train and validation data\n",
    "    train_data, date_feats = create_date_features(train_data)\n",
    "    val_data, _ = create_date_features(val_data)\n",
    "    \n",
    "    # Update feature columns\n",
    "    feature_cols = encoded_cat_features + date_feats\n",
    "\n",
    "    X_train = train_data[feature_cols]\n",
    "    X_val = val_data[feature_cols]\n",
    "    y_train = train_data['num_sold']\n",
    "    y_val = val_data['num_sold']\n",
    "    \n",
    "    # Train model\n",
    "    model = LGBMRegressor(n_estimators=1000,\n",
    "                         learning_rate=0.1,\n",
    "                         boosting_type='gbdt',\n",
    "                          verbosity=-1,\n",
    "                         categorical_feature=encoded_cat_features,\n",
    "                         random_state=42)\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        categorical_feature=encoded_cat_features\n",
    "    )\n",
    "    \n",
    "    # Make predictions\n",
    "    val_preds = model.predict(X_val)\n",
    "    \n",
    "    # Calculate and print MAPE with color\n",
    "    mape = mean_absolute_percentage_error(y_val, val_preds)\n",
    "    all_mapes.append(mape)\n",
    "    print(f\"{GREEN}Fold {fold + 1} MAPE: {mape:.4f}{RESET}\")\n",
    "    print()  # Add empty line after MAPE\n",
    "\n",
    "# Print average MAPE\n",
    "valid_mapes = [m for m in all_mapes if not np.isnan(m)]\n",
    "if valid_mapes:\n",
    "    print(f\"\\n{GREEN}Average MAPE across all folds: {np.mean(valid_mapes):.4f}{RESET}\")\n",
    "else:\n",
    "    print(\"\\nNo valid MAPE scores calculated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-01T02:14:31.552736Z",
     "iopub.status.busy": "2025-01-01T02:14:31.55232Z",
     "iopub.status.idle": "2025-01-01T02:14:31.560324Z",
     "shell.execute_reply": "2025-01-01T02:14:31.558825Z",
     "shell.execute_reply.started": "2025-01-01T02:14:31.552704Z"
    }
   },
   "source": [
    "## 🔮 Coming Soon...\n",
    "### The prediction phase is on the horizon!\n",
    "\n",
    "> **Don't forget to show your support with a vote if you find this notebook helpful!** \n",
    "> \n",
    "> *Every upvote motivates me to create better content* ⭐\n",
    "\n",
    "---\n",
    "*Thanks for reading! See you in the next notebook!* 👋"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10652996,
     "sourceId": 85723,
     "sourceType": "competition"
    },
    {
     "datasetId": 6406117,
     "sourceId": 10345089,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
